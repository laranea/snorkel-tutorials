{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting spouse mentions in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snorkel Introduction\n",
    "\n",
    "from collections import OrderedDict \n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cupy\n",
    "# import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import random\n",
    "import snorkel\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Make reproducible\n",
    "random.seed(1337)\n",
    "\n",
    "# Turn off TensorFlow logging messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"1337\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_LIMIT = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    'questions': {\n",
    "        'local': '../../data/stackoverflow/Questions.Tags.{}.parquet/part-00029-1ad544ea-abd4-4960-aa2c-7e0eb12cdb8e-c000.snappy.parquet',\n",
    "        's3': 's3://stackoverflow-events/08-05-2019/Questions.Tags.{}.parquet',\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define a set of paths for each step for local and S3\n",
    "PATH_SET = 'local' # 's3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_PostId</th>\n",
       "      <th>_AcceptedAnswerId</th>\n",
       "      <th>_Body</th>\n",
       "      <th>_Code</th>\n",
       "      <th>_Tags</th>\n",
       "      <th>_Label</th>\n",
       "      <th>_AnswerCount</th>\n",
       "      <th>_CommentCount</th>\n",
       "      <th>_FavoriteCount</th>\n",
       "      <th>_OwnerUserId</th>\n",
       "      <th>...</th>\n",
       "      <th>_AccountId</th>\n",
       "      <th>_UserId</th>\n",
       "      <th>_UserDisplayName</th>\n",
       "      <th>_UserDownVotes</th>\n",
       "      <th>_UserLocation</th>\n",
       "      <th>_ProfileImageUrl</th>\n",
       "      <th>_UserReputation</th>\n",
       "      <th>_UserUpVotes</th>\n",
       "      <th>_UserViews</th>\n",
       "      <th>_UserWebsiteUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>145263</td>\n",
       "      <td>145318.0</td>\n",
       "      <td>What is \"Total Functional Programming\"? Wikipe...</td>\n",
       "      <td></td>\n",
       "      <td>[programming-languages, functional-programming]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19784</td>\n",
       "      <td>...</td>\n",
       "      <td>10461</td>\n",
       "      <td>19784</td>\n",
       "      <td>Kyle Burton</td>\n",
       "      <td>19</td>\n",
       "      <td>Los Angeles, CA, USA</td>\n",
       "      <td>None</td>\n",
       "      <td>20298</td>\n",
       "      <td>1189</td>\n",
       "      <td>1066</td>\n",
       "      <td>http://asymmetrical-view.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16510</th>\n",
       "      <td>42169477</td>\n",
       "      <td>48052143.0</td>\n",
       "      <td>IntelliJ Firefox Web Extensions Development Am...</td>\n",
       "      <td></td>\n",
       "      <td>[javascript, firefox, intellij-idea]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5941389</td>\n",
       "      <td>...</td>\n",
       "      <td>7860946</td>\n",
       "      <td>5941389</td>\n",
       "      <td>JacketPotatoeFan</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.gravatar.com/avatar/2a50efd86b7252...</td>\n",
       "      <td>155</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26653</th>\n",
       "      <td>10251503</td>\n",
       "      <td>10287953.0</td>\n",
       "      <td>Is there any way to stop Apple OS' native styl...</td>\n",
       "      <td>-webkit-scrollbar</td>\n",
       "      <td>[css, ios, macos, focus, native]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1272033</td>\n",
       "      <td>...</td>\n",
       "      <td>1327505</td>\n",
       "      <td>1272033</td>\n",
       "      <td>InterfaceGuy</td>\n",
       "      <td>0</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>None</td>\n",
       "      <td>94</td>\n",
       "      <td>328</td>\n",
       "      <td>64</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _PostId  _AcceptedAnswerId  \\\n",
       "533      145263           145318.0   \n",
       "16510  42169477         48052143.0   \n",
       "26653  10251503         10287953.0   \n",
       "\n",
       "                                                   _Body              _Code  \\\n",
       "533    What is \"Total Functional Programming\"? Wikipe...                      \n",
       "16510  IntelliJ Firefox Web Extensions Development Am...                      \n",
       "26653  Is there any way to stop Apple OS' native styl...  -webkit-scrollbar   \n",
       "\n",
       "                                                 _Tags  _Label  _AnswerCount  \\\n",
       "533    [programming-languages, functional-programming]       0             3   \n",
       "16510             [javascript, firefox, intellij-idea]       0             1   \n",
       "26653                 [css, ios, macos, focus, native]       0             1   \n",
       "\n",
       "       _CommentCount  _FavoriteCount  _OwnerUserId  ... _AccountId  _UserId  \\\n",
       "533                3             9.0         19784  ...      10461    19784   \n",
       "16510              0             NaN       5941389  ...    7860946  5941389   \n",
       "26653              2             NaN       1272033  ...    1327505  1272033   \n",
       "\n",
       "       _UserDisplayName _UserDownVotes         _UserLocation  \\\n",
       "533         Kyle Burton             19  Los Angeles, CA, USA   \n",
       "16510  JacketPotatoeFan              0                  None   \n",
       "26653      InterfaceGuy              0     Mountain View, CA   \n",
       "\n",
       "                                        _ProfileImageUrl _UserReputation  \\\n",
       "533                                                 None           20298   \n",
       "16510  https://www.gravatar.com/avatar/2a50efd86b7252...             155   \n",
       "26653                                               None              94   \n",
       "\n",
       "       _UserUpVotes _UserViews                _UserWebsiteUrl  \n",
       "533            1189       1066  http://asymmetrical-view.com/  \n",
       "16510            24          1                           None  \n",
       "26653           328         64                                 \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATHS['questions'][PATH_SET].format(TAG_LIMIT)\n",
    "\n",
    "df = pd.read_parquet(\n",
    "    path, \n",
    "    engine='pyarrow',\n",
    "    \n",
    ")\n",
    "df_sample = df.sample(10000)\n",
    "df_sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Enable GPU support\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "# Download the spaCy english model\n",
    "spacy.cli.download('en_core_web_lg')\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "from spacy.pipeline import merge_entities\n",
    "\n",
    "nlp.add_pipe(merge_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['_SpacyDoc'] = df_sample['_Body'].apply(lambda x: nlp(x))\n",
    "df_sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "s = 'The program to do payroll was written in C++ and Perl.'\n",
    "d = nlp(s)\n",
    "tups = []\n",
    "for t in d:\n",
    "    tups.append((t.text, t.pos_))\n",
    "\n",
    "# Print words/parts-of-speech\n",
    "print([x for x in tups])\n",
    "\n",
    "# Render image diagrams\n",
    "displacy.render(d, style='dep', options={'compact': True, 'collapse_punct': True, 'distance': 90}, )\n",
    "displacy.render(d, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'POS': 'VERB'}, {'POS': 'ADP'}, {'POS': 'PROPN'}]\n",
    "matcher.add(\"VERB_ADP_PROPN\", None, pattern)\n",
    "\n",
    "for d in df_sample['_SpacyDoc']:\n",
    "    matches = matcher(d)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "        span = d[start:end]  # The matched span\n",
    "        for w in span:\n",
    "            print(w.text, w.pos_, w.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_sample['_SpacyDoc'].iloc[1]\n",
    "print(d.ents)\n",
    "e = d.ents[0]\n",
    "len(e.text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>spacy</th>\n",
       "      <th>start</th>\n",
       "      <th>start_char</th>\n",
       "      <th>left_tokens</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>right_tokens</th>\n",
       "      <th>end</th>\n",
       "      <th>end_char</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...</td>\n",
       "      <td>($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>(ionicplatform)</td>\n",
       "      <td>ionicplatform</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[nt, work, I, have, been]</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>(15, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...</td>\n",
       "      <td>($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...</td>\n",
       "      <td>45</td>\n",
       "      <td>212</td>\n",
       "      <td>[in, the, application, .., here, is]</td>\n",
       "      <td>(the index.html\\n\\n\\n)</td>\n",
       "      <td>the index.html\\n\\n\\n</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[here, is, the, app.js, \\n\\n]</td>\n",
       "      <td>46</td>\n",
       "      <td>229</td>\n",
       "      <td>(212, 229)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...</td>\n",
       "      <td>($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...</td>\n",
       "      <td>50</td>\n",
       "      <td>245</td>\n",
       "      <td>[is, the index.html\\n\\n\\n, and, here, is, the]</td>\n",
       "      <td>(app.js)</td>\n",
       "      <td>app.js</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, problem, is, with, the]</td>\n",
       "      <td>51</td>\n",
       "      <td>251</td>\n",
       "      <td>(245, 251)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google App Engine (GAE) - Flexible Environment - Jetty Issue After using , we receive a BUILD SU...</td>\n",
       "      <td>(Google App Engine, (, GAE, ), -, Flexible, Environment, -, Jetty, Issue, After, using, ,, we, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Google App Engine)</td>\n",
       "      <td>Google App Engine</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[GAE, ), -, Flexible, Environment]</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>(0, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google App Engine (GAE) - Flexible Environment - Jetty Issue After using , we receive a BUILD SU...</td>\n",
       "      <td>(Google App Engine, (, GAE, ), -, Flexible, Environment, -, Jetty, Issue, After, using, ,, we, r...</td>\n",
       "      <td>50</td>\n",
       "      <td>263</td>\n",
       "      <td>[to, the, wrong, directory, on, the]</td>\n",
       "      <td>(AppEngine)</td>\n",
       "      <td>AppEngine</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[causing, Jetty, to, not, be]</td>\n",
       "      <td>51</td>\n",
       "      <td>272</td>\n",
       "      <td>(263, 272)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  body  \\\n",
       "0  $scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...   \n",
       "1  $scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...   \n",
       "2  $scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...   \n",
       "3  Google App Engine (GAE) - Flexible Environment - Jetty Issue After using , we receive a BUILD SU...   \n",
       "4  Google App Engine (GAE) - Flexible Environment - Jetty Issue After using , we receive a BUILD SU...   \n",
       "\n",
       "                                                                                                 spacy  \\\n",
       "0  ($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...   \n",
       "1  ($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...   \n",
       "2  ($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...   \n",
       "3  (Google App Engine, (, GAE, ), -, Flexible, Environment, -, Jetty, Issue, After, using, ,, we, r...   \n",
       "4  (Google App Engine, (, GAE, ), -, Flexible, Environment, -, Jetty, Issue, After, using, ,, we, r...   \n",
       "\n",
       "   start  start_char                                     left_tokens  \\\n",
       "0      4          15                                              []   \n",
       "1     45         212            [in, the, application, .., here, is]   \n",
       "2     50         245  [is, the index.html\\n\\n\\n, and, here, is, the]   \n",
       "3      0           0                                              []   \n",
       "4     50         263            [to, the, wrong, directory, on, the]   \n",
       "\n",
       "                   entity           entity_text ent_type  wikidata_id  \\\n",
       "0         (ionicplatform)         ionicplatform      ORG            0   \n",
       "1  (the index.html\\n\\n\\n)  the index.html\\n\\n\\n      ORG            0   \n",
       "2                (app.js)                app.js      ORG            0   \n",
       "3     (Google App Engine)     Google App Engine      ORG            0   \n",
       "4             (AppEngine)             AppEngine      ORG            0   \n",
       "\n",
       "                         right_tokens  end  end_char         idx  \n",
       "0           [nt, work, I, have, been]    5        28    (15, 28)  \n",
       "1       [here, is, the, app.js, \\n\\n]   46       229  (212, 229)  \n",
       "2       [the, problem, is, with, the]   51       251  (245, 251)  \n",
       "3  [GAE, ), -, Flexible, Environment]    1        17     (0, 17)  \n",
       "4       [causing, Jetty, to, not, be]   51       272  (263, 272)  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_fields(df, window=5, field='_Body'):\n",
    "    \n",
    "    df['_SpacyDoc'] = df[field].apply(lambda x: nlp(x))\n",
    "    \n",
    "    # Produce the records in the demo for all entities we detect\n",
    "    candidates = []\n",
    "    for index, row in df.iterrows():\n",
    "        doc = row['_SpacyDoc']\n",
    "        for ent in doc.ents:\n",
    "            rec = {}\n",
    "            rec['body'] = doc.text\n",
    "            rec['spacy'] = doc\n",
    "            rec['start'] = ent.start\n",
    "            rec['start_char'] = doc[ent.start].idx\n",
    "            rec['left_tokens_text'] = [x.text for x in list(doc[ent.start - 1 - window : ent.start])]\n",
    "            rec['entity'] = ent\n",
    "            rec['entity_text'] = ent.text\n",
    "            rec['ent_type'] = ent.label_\n",
    "            rec['wikidata_id'] = ent.kb_id\n",
    "            rec['right_tokens_text'] = [x.text for x in list(doc[ent.end + 1 : ent.end + 1 + window])]\n",
    "            rec['end'] = ent.end\n",
    "            rec['end_char'] = doc[ent.start].idx + doc[ent.start].__len__()\n",
    "            rec['idx'] = (rec['start_char'], rec['end_char'])\n",
    "            if 'label' in row:\n",
    "                rec['label'] = row['label']\n",
    "\n",
    "            candidates.append(rec)\n",
    "\n",
    "    out_df = pd.DataFrame(candidates)\n",
    "\n",
    "    return out_df\n",
    "\n",
    "cand_df = make_fields(df_sample)\n",
    "cand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>spacy</th>\n",
       "      <th>start</th>\n",
       "      <th>start_char</th>\n",
       "      <th>left_tokens</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>right_tokens</th>\n",
       "      <th>end</th>\n",
       "      <th>end_char</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...</td>\n",
       "      <td>($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>(ionicplatform)</td>\n",
       "      <td>ionicplatform</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[nt, work, I, have, been]</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>(15, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...</td>\n",
       "      <td>($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...</td>\n",
       "      <td>45</td>\n",
       "      <td>212</td>\n",
       "      <td>[in, the, application, .., here, is]</td>\n",
       "      <td>(the index.html\\n\\n\\n)</td>\n",
       "      <td>the index.html\\n\\n\\n</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[here, is, the, app.js, \\n\\n]</td>\n",
       "      <td>46</td>\n",
       "      <td>229</td>\n",
       "      <td>(212, 229)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...</td>\n",
       "      <td>($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...</td>\n",
       "      <td>50</td>\n",
       "      <td>245</td>\n",
       "      <td>[is, the index.html\\n\\n\\n, and, here, is, the]</td>\n",
       "      <td>(app.js)</td>\n",
       "      <td>app.js</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, problem, is, with, the]</td>\n",
       "      <td>51</td>\n",
       "      <td>251</td>\n",
       "      <td>(245, 251)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google App Engine (GAE) - Flexible Environment - Jetty Issue After using , we receive a BUILD SU...</td>\n",
       "      <td>(Google App Engine, (, GAE, ), -, Flexible, Environment, -, Jetty, Issue, After, using, ,, we, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Google App Engine)</td>\n",
       "      <td>Google App Engine</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[GAE, ), -, Flexible, Environment]</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>(0, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google App Engine (GAE) - Flexible Environment - Jetty Issue After using , we receive a BUILD SU...</td>\n",
       "      <td>(Google App Engine, (, GAE, ), -, Flexible, Environment, -, Jetty, Issue, After, using, ,, we, r...</td>\n",
       "      <td>50</td>\n",
       "      <td>263</td>\n",
       "      <td>[to, the, wrong, directory, on, the]</td>\n",
       "      <td>(AppEngine)</td>\n",
       "      <td>AppEngine</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>[causing, Jetty, to, not, be]</td>\n",
       "      <td>51</td>\n",
       "      <td>272</td>\n",
       "      <td>(263, 272)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  body  \\\n",
       "0  $scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...   \n",
       "1  $scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...   \n",
       "2  $scope inside $ionicplatform doesnt work I have been developing an application, but this doesnt ...   \n",
       "3  Google App Engine (GAE) - Flexible Environment - Jetty Issue After using , we receive a BUILD SU...   \n",
       "4  Google App Engine (GAE) - Flexible Environment - Jetty Issue After using , we receive a BUILD SU...   \n",
       "\n",
       "                                                                                                 spacy  \\\n",
       "0  ($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...   \n",
       "1  ($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...   \n",
       "2  ($, scope, inside, $, ionicplatform, does, nt, work, I, have, been, developing, an, application,...   \n",
       "3  (Google App Engine, (, GAE, ), -, Flexible, Environment, -, Jetty, Issue, After, using, ,, we, r...   \n",
       "4  (Google App Engine, (, GAE, ), -, Flexible, Environment, -, Jetty, Issue, After, using, ,, we, r...   \n",
       "\n",
       "   start  start_char                                     left_tokens  \\\n",
       "0      4          15                                              []   \n",
       "1     45         212            [in, the, application, .., here, is]   \n",
       "2     50         245  [is, the index.html\\n\\n\\n, and, here, is, the]   \n",
       "3      0           0                                              []   \n",
       "4     50         263            [to, the, wrong, directory, on, the]   \n",
       "\n",
       "                   entity           entity_text ent_type  wikidata_id  \\\n",
       "0         (ionicplatform)         ionicplatform      ORG            0   \n",
       "1  (the index.html\\n\\n\\n)  the index.html\\n\\n\\n      ORG            0   \n",
       "2                (app.js)                app.js      ORG            0   \n",
       "3     (Google App Engine)     Google App Engine      ORG            0   \n",
       "4             (AppEngine)             AppEngine      ORG            0   \n",
       "\n",
       "                         right_tokens  end  end_char         idx  \n",
       "0           [nt, work, I, have, been]    5        28    (15, 28)  \n",
       "1       [here, is, the, app.js, \\n\\n]   46       229  (212, 229)  \n",
       "2       [the, problem, is, with, the]   51       251  (245, 251)  \n",
       "3  [GAE, ), -, Flexible, Environment]    1        17     (0, 17)  \n",
       "4       [causing, Jetty, to, not, be]   51       272  (263, 272)  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cand_df = cand_df.reindex()\n",
    "new_cand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# joined_df = cand_df.merge(\n",
    "#     df_dev,\n",
    "#     how='inner',\n",
    "#     suffixes=['_df', '_dev'],\n",
    "#     left_index=True,\n",
    "#     right_index=True,\n",
    "# )\n",
    "# joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45,339\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'{len(new_cand_df.index):,}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31737, 12), (13602, 12), (4702, 13), (31737,), (13602,), (4702,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = np.zeros((cand_df.shape[0]))\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    new_cand_df, \n",
    "    np.array(labels), \n",
    "    test_size=0.3,\n",
    "    random_state=1337,\n",
    ")\n",
    "\n",
    "# df_test, df_dev, y_test, y_dev = train_test_split(\n",
    "#     df_test_dev,\n",
    "#     y_test_dev,\n",
    "#     test_size=0.01,\n",
    "#     random_state=1337,\n",
    "# )\n",
    "\n",
    "df_train = df_train.sort_index()\n",
    "df_test  = df_test.sort_index()\n",
    "# df_dev   = df_dev.sort_index()\n",
    "\n",
    "df_dev = pd.read_csv('../../data/language.extractor.gold.2.csv')\n",
    "\n",
    "df_dev['df_index'] = df_dev[df_dev.columns[0]]\n",
    "df_dev = df_dev.set_index('df_index')\n",
    "\n",
    "df_dev['_SpacyDoc'] = df_dev['body'].apply(lambda x: nlp(x))\n",
    "\n",
    "# Produce the records in the demo for all entities we detect\n",
    "window = 5\n",
    "candidates, indexes = [], []\n",
    "for index, row in df_dev.iterrows():\n",
    "    doc = row['_SpacyDoc']\n",
    "    for ent in doc.ents:\n",
    "        with doc.retokenize() as retoken:\n",
    "            rec = {}\n",
    "            rec['body'] = doc.text\n",
    "            rec['spacy'] = doc\n",
    "            rec['entity'] = ent\n",
    "            rec['entity_text'] = ent.text\n",
    "            \n",
    "            rec['left_tokens'] = doc[\n",
    "                    max(0, ent.start - 1 - window) : \\\n",
    "                    ent.start\n",
    "            ]\n",
    "            rec['left_tokens_text'] = [x.text for x in rec['left_tokens']]\n",
    "            # print(\n",
    "            #     ent.text,\n",
    "            #     max(0, ent.start - 1 - window), \n",
    "            #     ent.start\n",
    "            # )\n",
    "            # rec['left_text'] = retoken.merge(rec['left_tokens'])\n",
    "\n",
    "            #print(ent.text, min(ent.end + 1, len(doc) - 1), min(ent.end + 1 + window, len(doc) - 1))\n",
    "            rec['right_tokens'] = doc[\n",
    "                    min(ent.end, len(doc) - 1) : \\\n",
    "                    min(ent.end + window, len(doc) - 1)\n",
    "            ]\n",
    "            rec['right_tokens_text'] = [x.text for x in rec['right_tokens']]\n",
    "            # rec['right_text'] = retoken.merge(rec['right_tokens'])\n",
    "\n",
    "            rec['start'] = ent.start\n",
    "\n",
    "            rec['entity'] = ent\n",
    "            rec['entity_text'] = ent.text\n",
    "            rec['ent_type'] = ent.label_\n",
    "            rec['wikidata_id'] = ent.kb_id\n",
    "            rec['end'] = ent.end\n",
    "            if 'label' in row:\n",
    "                rec['label'] = row['label']\n",
    "\n",
    "            candidates.append(rec)\n",
    "            indexes.append(index)\n",
    "\n",
    "df_dev = pd.DataFrame(candidates, index=indexes)\n",
    "y_dev = df_dev['label'].values\n",
    "\n",
    "df_train.shape, df_test.shape, df_dev.shape, y_train.shape, y_test.shape, y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>spacy</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>left_tokens</th>\n",
       "      <th>left_tokens_text</th>\n",
       "      <th>right_tokens</th>\n",
       "      <th>right_tokens_text</th>\n",
       "      <th>start</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(IBM, Websphere Portal)</td>\n",
       "      <td>IBM Websphere Portal</td>\n",
       "      <td>(JAR, of, the, portlet, taglibs, in)</td>\n",
       "      <td>[JAR, of, the, portlet, taglibs, in]</td>\n",
       "      <td>(7, ?, I, 'm, trying)</td>\n",
       "      <td>[7, ?, I, 'm, trying]</td>\n",
       "      <td>10</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(websphere)</td>\n",
       "      <td>websphere</td>\n",
       "      <td>('m, trying, to, build, portlets, for)</td>\n",
       "      <td>['m, trying, to, build, portlets, for]</td>\n",
       "      <td>(in, Eclipse, Juno, ., Everything)</td>\n",
       "      <td>[in, Eclipse, Juno, ., Everything]</td>\n",
       "      <td>21</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(Juno)</td>\n",
       "      <td>Juno</td>\n",
       "      <td>(build, portlets, for, websphere, in, Eclipse)</td>\n",
       "      <td>[build, portlets, for, websphere, in, Eclipse]</td>\n",
       "      <td>(., Everything, works, so, far)</td>\n",
       "      <td>[., Everything, works, so, far]</td>\n",
       "      <td>24</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(JSP)</td>\n",
       "      <td>JSP</td>\n",
       "      <td>(ok, ., \\n, But, in, my)</td>\n",
       "      <td>[ok, ., \\n, But, in, my]</td>\n",
       "      <td>(editor, I, get, a, lot)</td>\n",
       "      <td>[editor, I, get, a, lot]</td>\n",
       "      <td>46</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(JSP)</td>\n",
       "      <td>JSP</td>\n",
       "      <td>(of, warnings, :, \\n\\n, In, my)</td>\n",
       "      <td>[of, warnings, :, \\n\\n, In, my]</td>\n",
       "      <td>(file, I, 'm, using, the)</td>\n",
       "      <td>[file, I, 'm, using, the]</td>\n",
       "      <td>58</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    body  \\\n",
       "200  Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "200  Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "200  Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "200  Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "200  Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "\n",
       "                                                                                                   spacy  \\\n",
       "200  (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "200  (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "200  (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "200  (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "200  (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "\n",
       "                      entity           entity_text  \\\n",
       "200  (IBM, Websphere Portal)  IBM Websphere Portal   \n",
       "200              (websphere)             websphere   \n",
       "200                   (Juno)                  Juno   \n",
       "200                    (JSP)                   JSP   \n",
       "200                    (JSP)                   JSP   \n",
       "\n",
       "                                        left_tokens  \\\n",
       "200            (JAR, of, the, portlet, taglibs, in)   \n",
       "200          ('m, trying, to, build, portlets, for)   \n",
       "200  (build, portlets, for, websphere, in, Eclipse)   \n",
       "200                        (ok, ., \\n, But, in, my)   \n",
       "200                 (of, warnings, :, \\n\\n, In, my)   \n",
       "\n",
       "                                   left_tokens_text  \\\n",
       "200            [JAR, of, the, portlet, taglibs, in]   \n",
       "200          ['m, trying, to, build, portlets, for]   \n",
       "200  [build, portlets, for, websphere, in, Eclipse]   \n",
       "200                        [ok, ., \\n, But, in, my]   \n",
       "200                 [of, warnings, :, \\n\\n, In, my]   \n",
       "\n",
       "                           right_tokens                   right_tokens_text  \\\n",
       "200               (7, ?, I, 'm, trying)               [7, ?, I, 'm, trying]   \n",
       "200  (in, Eclipse, Juno, ., Everything)  [in, Eclipse, Juno, ., Everything]   \n",
       "200     (., Everything, works, so, far)     [., Everything, works, so, far]   \n",
       "200            (editor, I, get, a, lot)            [editor, I, get, a, lot]   \n",
       "200           (file, I, 'm, using, the)           [file, I, 'm, using, the]   \n",
       "\n",
       "     start ent_type  wikidata_id  end  label  \n",
       "200     10      ORG            0   12      0  \n",
       "200     21  PRODUCT            0   22      0  \n",
       "200     24  PRODUCT            0   25      0  \n",
       "200     46      ORG            0   47      0  \n",
       "200     58      ORG            0   59      0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gold = df_dev[['body', 'left_tokens', 'entity_text', 'right_tokens']]\n",
    "\n",
    "# df_gold['left_tokens']  = df_gold['left_tokens'].apply(lambda x: ' '.join(x))\n",
    "# df_gold['right_tokens'] = df_gold['right_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# df_gold.to_csv('../../data/language.extractor.gold.2.csv')\n",
    "\n",
    "# df_gold.head()\n",
    "\n",
    "# df_gold_label = pd.read_csv('../../data/language.extractor.gold.2.csv')\n",
    "# df_gold_label = df_gold_label.set_index('index')\n",
    "\n",
    "# # joined_df = new_cand_df.merge(\n",
    "# #     df_gold_label,\n",
    "# #     how='inner',\n",
    "# #     suffixes=['', '_labeled'],\n",
    "# #     left_index=True,\n",
    "# #     right_index=True,\n",
    "# # )\n",
    "\n",
    "# # df_dev = joined_df.drop(['body_labeled', 'left_tokens_labeled', 'entity_text_labeled', 'right_tokens_labeled'], axis=1)\n",
    "\n",
    "# y_dev = df_dev['label'].values\n",
    "# y_dev\n",
    "\n",
    "# df_gold_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## In this tutorial, we will see how Snorkel can be used for Information Extraction. We will walk through an example text classification task for information extraction, where we use labeling functions involving keywords and distant supervision.\n",
    "\n",
    "### Classification Task\n",
    "<img src=\"imgs/sentence.jpg\" width=\"700px;\" onerror=\"this.onerror=null; this.src='/doks-theme/assets/images/sentence.jpg';\" align=\"center\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "We want to classify each __candidate__ or pair of people mentioned in a sentence, as being married at some point or not.\n",
    "\n",
    "In the above example, our candidate represents the possible relation `(Barack Obama, Michelle Obama)`. As readers, we know this mention is true due to external knowledge and the keyword of `wedding` occuring later in the sentence.\n",
    "We begin with some basic setup and data downloading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "\n",
    "# if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "#     os.chdir(\"spouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import load_data\n",
    "\n",
    "# ((tf_dev, ty_dev), tf_train, (tf_test, ty_test)) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_dev\n",
    "\n",
    "import pickle\n",
    "\n",
    "test_data = pickle.load('data/dev_data.pkl')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Data:** `df_dev`, `df_train`, and `df_test` are `Pandas DataFrame` objects, where each row represents a particular __candidate__. For our problem, a candidate consists of a sentence, and two people mentioned in the sentence. The DataFrames contain the fields `sentence`, which refers to the sentence of the candidate, `tokens`, the tokenized form of the sentence, and `person1_word_idx` and `person2_word_idx`, which represent `[start, end]` indices in the tokens at which the first and second person's name appear, respectively.\n",
    "\n",
    "We also have certain **preprocessed fields**, that we discuss a few cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>spacy</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>left_tokens</th>\n",
       "      <th>left_tokens_text</th>\n",
       "      <th>right_tokens</th>\n",
       "      <th>right_tokens_text</th>\n",
       "      <th>start</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(IBM, Websphere Portal)</td>\n",
       "      <td>IBM Websphere Portal</td>\n",
       "      <td>(JAR, of, the, portlet, taglibs, in)</td>\n",
       "      <td>[JAR, of, the, portlet, taglibs, in]</td>\n",
       "      <td>(7, ?, I, 'm, trying)</td>\n",
       "      <td>[7, ?, I, 'm, trying]</td>\n",
       "      <td>10</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(websphere)</td>\n",
       "      <td>websphere</td>\n",
       "      <td>('m, trying, to, build, portlets, for)</td>\n",
       "      <td>['m, trying, to, build, portlets, for]</td>\n",
       "      <td>(in, Eclipse, Juno, ., Everything)</td>\n",
       "      <td>[in, Eclipse, Juno, ., Everything]</td>\n",
       "      <td>21</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(Juno)</td>\n",
       "      <td>Juno</td>\n",
       "      <td>(build, portlets, for, websphere, in, Eclipse)</td>\n",
       "      <td>[build, portlets, for, websphere, in, Eclipse]</td>\n",
       "      <td>(., Everything, works, so, far)</td>\n",
       "      <td>[., Everything, works, so, far]</td>\n",
       "      <td>24</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(JSP)</td>\n",
       "      <td>JSP</td>\n",
       "      <td>(ok, ., \\n, But, in, my)</td>\n",
       "      <td>[ok, ., \\n, But, in, my]</td>\n",
       "      <td>(editor, I, get, a, lot)</td>\n",
       "      <td>[editor, I, get, a, lot]</td>\n",
       "      <td>46</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...</td>\n",
       "      <td>(Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...</td>\n",
       "      <td>(JSP)</td>\n",
       "      <td>JSP</td>\n",
       "      <td>(of, warnings, :, \\n\\n, In, my)</td>\n",
       "      <td>[of, warnings, :, \\n\\n, In, my]</td>\n",
       "      <td>(file, I, 'm, using, the)</td>\n",
       "      <td>[file, I, 'm, using, the]</td>\n",
       "      <td>58</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Checking File is Open in Delphi Is there a way to check if a file has been opened by ReWrite in ...</td>\n",
       "      <td>(Checking, File, is, Open, in, Delphi, Is, there, a, way, to, check, if, a, file, has, been, ope...</td>\n",
       "      <td>(Delphi)</td>\n",
       "      <td>Delphi</td>\n",
       "      <td>(Checking, File, is, Open, in)</td>\n",
       "      <td>[Checking, File, is, Open, in]</td>\n",
       "      <td>(Is, there, a, way, to)</td>\n",
       "      <td>[Is, there, a, way, to]</td>\n",
       "      <td>5</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Checking File is Open in Delphi Is there a way to check if a file has been opened by ReWrite in ...</td>\n",
       "      <td>(Checking, File, is, Open, in, Delphi, Is, there, a, way, to, check, if, a, file, has, been, ope...</td>\n",
       "      <td>(ReWrite)</td>\n",
       "      <td>ReWrite</td>\n",
       "      <td>(a, file, has, been, opened, by)</td>\n",
       "      <td>[a, file, has, been, opened, by]</td>\n",
       "      <td>(in, Delphi, ?, \\n, Code)</td>\n",
       "      <td>[in, Delphi, ?, \\n, Code]</td>\n",
       "      <td>19</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Checking File is Open in Delphi Is there a way to check if a file has been opened by ReWrite in ...</td>\n",
       "      <td>(Checking, File, is, Open, in, Delphi, Is, there, a, way, to, check, if, a, file, has, been, ope...</td>\n",
       "      <td>(Delphi)</td>\n",
       "      <td>Delphi</td>\n",
       "      <td>(has, been, opened, by, ReWrite, in)</td>\n",
       "      <td>[has, been, opened, by, ReWrite, in]</td>\n",
       "      <td>(?, \\n, Code, would, go)</td>\n",
       "      <td>[?, \\n, Code, would, go]</td>\n",
       "      <td>21</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>How can I use Git with multiple remote repositories? I use currently use Heroku for rails hostin...</td>\n",
       "      <td>(How, can, I, use, Git, with, multiple, remote, repositories, ?, I, use, currently, use, Heroku,...</td>\n",
       "      <td>(Heroku)</td>\n",
       "      <td>Heroku</td>\n",
       "      <td>(repositories, ?, I, use, currently, use)</td>\n",
       "      <td>[repositories, ?, I, use, currently, use]</td>\n",
       "      <td>(for, rails, hosting, which, uses)</td>\n",
       "      <td>[for, rails, hosting, which, uses]</td>\n",
       "      <td>14</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>How can I use Git with multiple remote repositories? I use currently use Heroku for rails hostin...</td>\n",
       "      <td>(How, can, I, use, Git, with, multiple, remote, repositories, ?, I, use, currently, use, Heroku,...</td>\n",
       "      <td>(1)</td>\n",
       "      <td>1</td>\n",
       "      <td>( , I, would, like, to, have)</td>\n",
       "      <td>[ , I, would, like, to, have]</td>\n",
       "      <td>(local, folder, that, has, my)</td>\n",
       "      <td>[local, folder, that, has, my]</td>\n",
       "      <td>54</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>How can I use Git with multiple remote repositories? I use currently use Heroku for rails hostin...</td>\n",
       "      <td>(How, can, I, use, Git, with, multiple, remote, repositories, ?, I, use, currently, use, Heroku,...</td>\n",
       "      <td>(Heroku)</td>\n",
       "      <td>Heroku</td>\n",
       "      <td>(commit, my, changes, to, either, the)</td>\n",
       "      <td>[commit, my, changes, to, either, the]</td>\n",
       "      <td>(repository, ,, or, my, hosted)</td>\n",
       "      <td>[repository, ,, or, my, hosted]</td>\n",
       "      <td>76</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>How can I use Git with multiple remote repositories? I use currently use Heroku for rails hostin...</td>\n",
       "      <td>(How, can, I, use, Git, with, multiple, remote, repositories, ?, I, use, currently, use, Heroku,...</td>\n",
       "      <td>(Team System)</td>\n",
       "      <td>Team System</td>\n",
       "      <td>(that, I, am, familiar, with, how)</td>\n",
       "      <td>[that, I, am, familiar, with, how]</td>\n",
       "      <td>(does, source, control, and, am)</td>\n",
       "      <td>[does, source, control, and, am]</td>\n",
       "      <td>102</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...</td>\n",
       "      <td>(Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...</td>\n",
       "      <td>(Android 4)</td>\n",
       "      <td>Android 4</td>\n",
       "      <td>(passed, to, search, results, activity, on)</td>\n",
       "      <td>[passed, to, search, results, activity, on]</td>\n",
       "      <td>(when, using, voice, search, ?)</td>\n",
       "      <td>[when, using, voice, search, ?]</td>\n",
       "      <td>11</td>\n",
       "      <td>LAW</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...</td>\n",
       "      <td>(Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...</td>\n",
       "      <td>(Android 2.2)</td>\n",
       "      <td>Android 2.2</td>\n",
       "      <td>(searchable, app, that, works, fine, on)</td>\n",
       "      <td>[searchable, app, that, works, fine, on]</td>\n",
       "      <td>(.,  , I, can, search)</td>\n",
       "      <td>[.,  , I, can, search]</td>\n",
       "      <td>26</td>\n",
       "      <td>LAW</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...</td>\n",
       "      <td>(Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...</td>\n",
       "      <td>(Android 4.0.4)</td>\n",
       "      <td>Android 4.0.4</td>\n",
       "      <td>(same, app, on, a, device, running)</td>\n",
       "      <td>[same, app, on, a, device, running]</td>\n",
       "      <td>((, I, 've, tried, two)</td>\n",
       "      <td>[(, I, 've, tried, two]</td>\n",
       "      <td>78</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...</td>\n",
       "      <td>(Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...</td>\n",
       "      <td>(two)</td>\n",
       "      <td>two</td>\n",
       "      <td>(running, Android 4.0.4, (, I, 've, tried)</td>\n",
       "      <td>[running, Android 4.0.4, (, I, 've, tried]</td>\n",
       "      <td>(different, devices, -, one, HTC)</td>\n",
       "      <td>[different, devices, -, one, HTC]</td>\n",
       "      <td>83</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...</td>\n",
       "      <td>(Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...</td>\n",
       "      <td>(one)</td>\n",
       "      <td>one</td>\n",
       "      <td>('ve, tried, two, different, devices, -)</td>\n",
       "      <td>['ve, tried, two, different, devices, -]</td>\n",
       "      <td>(HTC, and, one, Samsung, ))</td>\n",
       "      <td>[HTC, and, one, Samsung, )]</td>\n",
       "      <td>87</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...</td>\n",
       "      <td>(Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...</td>\n",
       "      <td>(HTC)</td>\n",
       "      <td>HTC</td>\n",
       "      <td>(tried, two, different, devices, -, one)</td>\n",
       "      <td>[tried, two, different, devices, -, one]</td>\n",
       "      <td>(and, one, Samsung, ), the)</td>\n",
       "      <td>[and, one, Samsung, ), the]</td>\n",
       "      <td>88</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...</td>\n",
       "      <td>(Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...</td>\n",
       "      <td>(one)</td>\n",
       "      <td>one</td>\n",
       "      <td>(different, devices, -, one, HTC, and)</td>\n",
       "      <td>[different, devices, -, one, HTC, and]</td>\n",
       "      <td>(Samsung, ), the, bundle, is)</td>\n",
       "      <td>[Samsung, ), the, bundle, is]</td>\n",
       "      <td>90</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...</td>\n",
       "      <td>(Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...</td>\n",
       "      <td>(Samsung)</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>(devices, -, one, HTC, and, one)</td>\n",
       "      <td>[devices, -, one, HTC, and, one]</td>\n",
       "      <td>(), the, bundle, is, only)</td>\n",
       "      <td>[), the, bundle, is, only]</td>\n",
       "      <td>91</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...</td>\n",
       "      <td>(What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...</td>\n",
       "      <td>(CSS Grid)</td>\n",
       "      <td>CSS Grid</td>\n",
       "      <td>(you, believe, to, be, the, best)</td>\n",
       "      <td>[you, believe, to, be, the, best]</td>\n",
       "      <td>(system, and, why, ?, I)</td>\n",
       "      <td>[system, and, why, ?, I]</td>\n",
       "      <td>8</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...</td>\n",
       "      <td>(What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...</td>\n",
       "      <td>(Nicole Sullivan's)</td>\n",
       "      <td>Nicole Sullivan's</td>\n",
       "      <td>(why, ?, I, 've, been, using)</td>\n",
       "      <td>[why, ?, I, 've, been, using]</td>\n",
       "      <td>(\", Object Oriented, \", CSS, grid)</td>\n",
       "      <td>[\", Object Oriented, \", CSS, grid]</td>\n",
       "      <td>17</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...</td>\n",
       "      <td>(What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...</td>\n",
       "      <td>(Object Oriented)</td>\n",
       "      <td>Object Oriented</td>\n",
       "      <td>(I, 've, been, using, Nicole Sullivan's, \")</td>\n",
       "      <td>[I, 've, been, using, Nicole Sullivan's, \"]</td>\n",
       "      <td>(\", CSS, grid, for, a)</td>\n",
       "      <td>[\", CSS, grid, for, a]</td>\n",
       "      <td>19</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...</td>\n",
       "      <td>(What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...</td>\n",
       "      <td>(960)</td>\n",
       "      <td>960</td>\n",
       "      <td>(out, there, ;, in, particular, the)</td>\n",
       "      <td>[out, there, ;, in, particular, the]</td>\n",
       "      <td>(Grid System, and, the, Yahoo, !)</td>\n",
       "      <td>[Grid System, and, the, Yahoo, !]</td>\n",
       "      <td>68</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...</td>\n",
       "      <td>(What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...</td>\n",
       "      <td>(Grid System)</td>\n",
       "      <td>Grid System</td>\n",
       "      <td>(there, ;, in, particular, the, 960)</td>\n",
       "      <td>[there, ;, in, particular, the, 960]</td>\n",
       "      <td>(and, the, Yahoo, !, UI Library)</td>\n",
       "      <td>[and, the, Yahoo, !, UI Library]</td>\n",
       "      <td>69</td>\n",
       "      <td>LOC</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...</td>\n",
       "      <td>(What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...</td>\n",
       "      <td>(Yahoo)</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>(particular, the, 960, Grid System, and, the)</td>\n",
       "      <td>[particular, the, 960, Grid System, and, the]</td>\n",
       "      <td>(!, UI Library, ., \\n, I)</td>\n",
       "      <td>[!, UI Library, ., \\n, I]</td>\n",
       "      <td>72</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...</td>\n",
       "      <td>(What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...</td>\n",
       "      <td>(UI Library)</td>\n",
       "      <td>UI Library</td>\n",
       "      <td>(960, Grid System, and, the, Yahoo, !)</td>\n",
       "      <td>[960, Grid System, and, the, Yahoo, !]</td>\n",
       "      <td>(., \\n, I, 'm, looking)</td>\n",
       "      <td>[., \\n, I, 'm, looking]</td>\n",
       "      <td>74</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>Sending POST data with curl and php Greets.\\nSo, I'm running Fedora Core 8 on an Amazon EC2. I i...</td>\n",
       "      <td>(Sending, POST, data, with, curl, and, php, Greets, ., \\n, So, ,, I, 'm, running, Fedora Core 8,...</td>\n",
       "      <td>(POST)</td>\n",
       "      <td>POST</td>\n",
       "      <td>(Sending)</td>\n",
       "      <td>[Sending]</td>\n",
       "      <td>(data, with, curl, and, php)</td>\n",
       "      <td>[data, with, curl, and, php]</td>\n",
       "      <td>1</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>Sending POST data with curl and php Greets.\\nSo, I'm running Fedora Core 8 on an Amazon EC2. I i...</td>\n",
       "      <td>(Sending, POST, data, with, curl, and, php, Greets, ., \\n, So, ,, I, 'm, running, Fedora Core 8,...</td>\n",
       "      <td>(Fedora Core 8)</td>\n",
       "      <td>Fedora Core 8</td>\n",
       "      <td>(\\n, So, ,, I, 'm, running)</td>\n",
       "      <td>[\\n, So, ,, I, 'm, running]</td>\n",
       "      <td>(on, an, Amazon, EC2, .)</td>\n",
       "      <td>[on, an, Amazon, EC2, .]</td>\n",
       "      <td>15</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>Sending POST data with curl and php Greets.\\nSo, I'm running Fedora Core 8 on an Amazon EC2. I i...</td>\n",
       "      <td>(Sending, POST, data, with, curl, and, php, Greets, ., \\n, So, ,, I, 'm, running, Fedora Core 8,...</td>\n",
       "      <td>(Amazon)</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>(I, 'm, running, Fedora Core 8, on, an)</td>\n",
       "      <td>[I, 'm, running, Fedora Core 8, on, an]</td>\n",
       "      <td>(EC2, ., I, installed,   )</td>\n",
       "      <td>[EC2, ., I, installed,   ]</td>\n",
       "      <td>18</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     body  \\\n",
       "200   Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "200   Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "200   Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "200   Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "200   Where is the defining JAR of the portlet taglibs in IBM Websphere Portal 7? I'm trying to build ...   \n",
       "328   Checking File is Open in Delphi Is there a way to check if a file has been opened by ReWrite in ...   \n",
       "328   Checking File is Open in Delphi Is there a way to check if a file has been opened by ReWrite in ...   \n",
       "328   Checking File is Open in Delphi Is there a way to check if a file has been opened by ReWrite in ...   \n",
       "871   How can I use Git with multiple remote repositories? I use currently use Heroku for rails hostin...   \n",
       "871   How can I use Git with multiple remote repositories? I use currently use Heroku for rails hostin...   \n",
       "871   How can I use Git with multiple remote repositories? I use currently use Heroku for rails hostin...   \n",
       "871   How can I use Git with multiple remote repositories? I use currently use Heroku for rails hostin...   \n",
       "1307  Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...   \n",
       "1307  Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...   \n",
       "1307  Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...   \n",
       "1307  Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...   \n",
       "1307  Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...   \n",
       "1307  Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...   \n",
       "1307  Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...   \n",
       "1307  Why is APP_DATA bundle not passed to search results activity on Android 4 when using voice searc...   \n",
       "2071  What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...   \n",
       "2071  What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...   \n",
       "2071  What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...   \n",
       "2071  What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...   \n",
       "2071  What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...   \n",
       "2071  What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...   \n",
       "2071  What do you believe to be the best CSS Grid system and why? I've been using Nicole Sullivan's \"O...   \n",
       "2641  Sending POST data with curl and php Greets.\\nSo, I'm running Fedora Core 8 on an Amazon EC2. I i...   \n",
       "2641  Sending POST data with curl and php Greets.\\nSo, I'm running Fedora Core 8 on an Amazon EC2. I i...   \n",
       "2641  Sending POST data with curl and php Greets.\\nSo, I'm running Fedora Core 8 on an Amazon EC2. I i...   \n",
       "\n",
       "                                                                                                    spacy  \\\n",
       "200   (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "200   (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "200   (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "200   (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "200   (Where, is, the, defining, JAR, of, the, portlet, taglibs, in, IBM, Websphere Portal, 7, ?, I, '...   \n",
       "328   (Checking, File, is, Open, in, Delphi, Is, there, a, way, to, check, if, a, file, has, been, ope...   \n",
       "328   (Checking, File, is, Open, in, Delphi, Is, there, a, way, to, check, if, a, file, has, been, ope...   \n",
       "328   (Checking, File, is, Open, in, Delphi, Is, there, a, way, to, check, if, a, file, has, been, ope...   \n",
       "871   (How, can, I, use, Git, with, multiple, remote, repositories, ?, I, use, currently, use, Heroku,...   \n",
       "871   (How, can, I, use, Git, with, multiple, remote, repositories, ?, I, use, currently, use, Heroku,...   \n",
       "871   (How, can, I, use, Git, with, multiple, remote, repositories, ?, I, use, currently, use, Heroku,...   \n",
       "871   (How, can, I, use, Git, with, multiple, remote, repositories, ?, I, use, currently, use, Heroku,...   \n",
       "1307  (Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...   \n",
       "1307  (Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...   \n",
       "1307  (Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...   \n",
       "1307  (Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...   \n",
       "1307  (Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...   \n",
       "1307  (Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...   \n",
       "1307  (Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...   \n",
       "1307  (Why, is, APP_DATA, bundle, not, passed, to, search, results, activity, on, Android 4, when, usi...   \n",
       "2071  (What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...   \n",
       "2071  (What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...   \n",
       "2071  (What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...   \n",
       "2071  (What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...   \n",
       "2071  (What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...   \n",
       "2071  (What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...   \n",
       "2071  (What, do, you, believe, to, be, the, best, CSS Grid, system, and, why, ?, I, 've, been, using, ...   \n",
       "2641  (Sending, POST, data, with, curl, and, php, Greets, ., \\n, So, ,, I, 'm, running, Fedora Core 8,...   \n",
       "2641  (Sending, POST, data, with, curl, and, php, Greets, ., \\n, So, ,, I, 'm, running, Fedora Core 8,...   \n",
       "2641  (Sending, POST, data, with, curl, and, php, Greets, ., \\n, So, ,, I, 'm, running, Fedora Core 8,...   \n",
       "\n",
       "                       entity           entity_text  \\\n",
       "200   (IBM, Websphere Portal)  IBM Websphere Portal   \n",
       "200               (websphere)             websphere   \n",
       "200                    (Juno)                  Juno   \n",
       "200                     (JSP)                   JSP   \n",
       "200                     (JSP)                   JSP   \n",
       "328                  (Delphi)                Delphi   \n",
       "328                 (ReWrite)               ReWrite   \n",
       "328                  (Delphi)                Delphi   \n",
       "871                  (Heroku)                Heroku   \n",
       "871                       (1)                     1   \n",
       "871                  (Heroku)                Heroku   \n",
       "871             (Team System)           Team System   \n",
       "1307              (Android 4)             Android 4   \n",
       "1307            (Android 2.2)           Android 2.2   \n",
       "1307          (Android 4.0.4)         Android 4.0.4   \n",
       "1307                    (two)                   two   \n",
       "1307                    (one)                   one   \n",
       "1307                    (HTC)                   HTC   \n",
       "1307                    (one)                   one   \n",
       "1307                (Samsung)               Samsung   \n",
       "2071               (CSS Grid)              CSS Grid   \n",
       "2071      (Nicole Sullivan's)     Nicole Sullivan's   \n",
       "2071        (Object Oriented)       Object Oriented   \n",
       "2071                    (960)                   960   \n",
       "2071            (Grid System)           Grid System   \n",
       "2071                  (Yahoo)                 Yahoo   \n",
       "2071             (UI Library)            UI Library   \n",
       "2641                   (POST)                  POST   \n",
       "2641          (Fedora Core 8)         Fedora Core 8   \n",
       "2641                 (Amazon)                Amazon   \n",
       "\n",
       "                                         left_tokens  \\\n",
       "200             (JAR, of, the, portlet, taglibs, in)   \n",
       "200           ('m, trying, to, build, portlets, for)   \n",
       "200   (build, portlets, for, websphere, in, Eclipse)   \n",
       "200                         (ok, ., \\n, But, in, my)   \n",
       "200                  (of, warnings, :, \\n\\n, In, my)   \n",
       "328                   (Checking, File, is, Open, in)   \n",
       "328                 (a, file, has, been, opened, by)   \n",
       "328             (has, been, opened, by, ReWrite, in)   \n",
       "871        (repositories, ?, I, use, currently, use)   \n",
       "871                    ( , I, would, like, to, have)   \n",
       "871           (commit, my, changes, to, either, the)   \n",
       "871               (that, I, am, familiar, with, how)   \n",
       "1307     (passed, to, search, results, activity, on)   \n",
       "1307        (searchable, app, that, works, fine, on)   \n",
       "1307             (same, app, on, a, device, running)   \n",
       "1307      (running, Android 4.0.4, (, I, 've, tried)   \n",
       "1307        ('ve, tried, two, different, devices, -)   \n",
       "1307        (tried, two, different, devices, -, one)   \n",
       "1307          (different, devices, -, one, HTC, and)   \n",
       "1307                (devices, -, one, HTC, and, one)   \n",
       "2071               (you, believe, to, be, the, best)   \n",
       "2071                   (why, ?, I, 've, been, using)   \n",
       "2071     (I, 've, been, using, Nicole Sullivan's, \")   \n",
       "2071            (out, there, ;, in, particular, the)   \n",
       "2071            (there, ;, in, particular, the, 960)   \n",
       "2071   (particular, the, 960, Grid System, and, the)   \n",
       "2071          (960, Grid System, and, the, Yahoo, !)   \n",
       "2641                                       (Sending)   \n",
       "2641                     (\\n, So, ,, I, 'm, running)   \n",
       "2641         (I, 'm, running, Fedora Core 8, on, an)   \n",
       "\n",
       "                                    left_tokens_text  \\\n",
       "200             [JAR, of, the, portlet, taglibs, in]   \n",
       "200           ['m, trying, to, build, portlets, for]   \n",
       "200   [build, portlets, for, websphere, in, Eclipse]   \n",
       "200                         [ok, ., \\n, But, in, my]   \n",
       "200                  [of, warnings, :, \\n\\n, In, my]   \n",
       "328                   [Checking, File, is, Open, in]   \n",
       "328                 [a, file, has, been, opened, by]   \n",
       "328             [has, been, opened, by, ReWrite, in]   \n",
       "871        [repositories, ?, I, use, currently, use]   \n",
       "871                    [ , I, would, like, to, have]   \n",
       "871           [commit, my, changes, to, either, the]   \n",
       "871               [that, I, am, familiar, with, how]   \n",
       "1307     [passed, to, search, results, activity, on]   \n",
       "1307        [searchable, app, that, works, fine, on]   \n",
       "1307             [same, app, on, a, device, running]   \n",
       "1307      [running, Android 4.0.4, (, I, 've, tried]   \n",
       "1307        ['ve, tried, two, different, devices, -]   \n",
       "1307        [tried, two, different, devices, -, one]   \n",
       "1307          [different, devices, -, one, HTC, and]   \n",
       "1307                [devices, -, one, HTC, and, one]   \n",
       "2071               [you, believe, to, be, the, best]   \n",
       "2071                   [why, ?, I, 've, been, using]   \n",
       "2071     [I, 've, been, using, Nicole Sullivan's, \"]   \n",
       "2071            [out, there, ;, in, particular, the]   \n",
       "2071            [there, ;, in, particular, the, 960]   \n",
       "2071   [particular, the, 960, Grid System, and, the]   \n",
       "2071          [960, Grid System, and, the, Yahoo, !]   \n",
       "2641                                       [Sending]   \n",
       "2641                     [\\n, So, ,, I, 'm, running]   \n",
       "2641         [I, 'm, running, Fedora Core 8, on, an]   \n",
       "\n",
       "                            right_tokens                   right_tokens_text  \\\n",
       "200                (7, ?, I, 'm, trying)               [7, ?, I, 'm, trying]   \n",
       "200   (in, Eclipse, Juno, ., Everything)  [in, Eclipse, Juno, ., Everything]   \n",
       "200      (., Everything, works, so, far)     [., Everything, works, so, far]   \n",
       "200             (editor, I, get, a, lot)            [editor, I, get, a, lot]   \n",
       "200            (file, I, 'm, using, the)           [file, I, 'm, using, the]   \n",
       "328              (Is, there, a, way, to)             [Is, there, a, way, to]   \n",
       "328            (in, Delphi, ?, \\n, Code)           [in, Delphi, ?, \\n, Code]   \n",
       "328             (?, \\n, Code, would, go)            [?, \\n, Code, would, go]   \n",
       "871   (for, rails, hosting, which, uses)  [for, rails, hosting, which, uses]   \n",
       "871       (local, folder, that, has, my)      [local, folder, that, has, my]   \n",
       "871      (repository, ,, or, my, hosted)     [repository, ,, or, my, hosted]   \n",
       "871     (does, source, control, and, am)    [does, source, control, and, am]   \n",
       "1307     (when, using, voice, search, ?)     [when, using, voice, search, ?]   \n",
       "1307              (.,  , I, can, search)              [.,  , I, can, search]   \n",
       "1307             ((, I, 've, tried, two)             [(, I, 've, tried, two]   \n",
       "1307   (different, devices, -, one, HTC)   [different, devices, -, one, HTC]   \n",
       "1307         (HTC, and, one, Samsung, ))         [HTC, and, one, Samsung, )]   \n",
       "1307         (and, one, Samsung, ), the)         [and, one, Samsung, ), the]   \n",
       "1307       (Samsung, ), the, bundle, is)       [Samsung, ), the, bundle, is]   \n",
       "1307          (), the, bundle, is, only)          [), the, bundle, is, only]   \n",
       "2071            (system, and, why, ?, I)            [system, and, why, ?, I]   \n",
       "2071  (\", Object Oriented, \", CSS, grid)  [\", Object Oriented, \", CSS, grid]   \n",
       "2071              (\", CSS, grid, for, a)              [\", CSS, grid, for, a]   \n",
       "2071   (Grid System, and, the, Yahoo, !)   [Grid System, and, the, Yahoo, !]   \n",
       "2071    (and, the, Yahoo, !, UI Library)    [and, the, Yahoo, !, UI Library]   \n",
       "2071           (!, UI Library, ., \\n, I)           [!, UI Library, ., \\n, I]   \n",
       "2071             (., \\n, I, 'm, looking)             [., \\n, I, 'm, looking]   \n",
       "2641        (data, with, curl, and, php)        [data, with, curl, and, php]   \n",
       "2641            (on, an, Amazon, EC2, .)            [on, an, Amazon, EC2, .]   \n",
       "2641          (EC2, ., I, installed,   )          [EC2, ., I, installed,   ]   \n",
       "\n",
       "      start     ent_type  wikidata_id  end  label  \n",
       "200      10          ORG            0   12      0  \n",
       "200      21      PRODUCT            0   22      0  \n",
       "200      24      PRODUCT            0   25      0  \n",
       "200      46          ORG            0   47      0  \n",
       "200      58          ORG            0   59      0  \n",
       "328       5          ORG            0    6      1  \n",
       "328      19          ORG            0   20      1  \n",
       "328      21          ORG            0   22      1  \n",
       "871      14          ORG            0   15      0  \n",
       "871      54     CARDINAL            0   55      0  \n",
       "871      76          ORG            0   77      0  \n",
       "871     102          ORG            0  103      0  \n",
       "1307     11          LAW            0   12      0  \n",
       "1307     26          LAW            0   27      0  \n",
       "1307     78      PRODUCT            0   79      0  \n",
       "1307     83     CARDINAL            0   84      0  \n",
       "1307     87     CARDINAL            0   88      0  \n",
       "1307     88      PRODUCT            0   89      0  \n",
       "1307     90     CARDINAL            0   91      0  \n",
       "1307     91          ORG            0   92      0  \n",
       "2071      8      PRODUCT            0    9      0  \n",
       "2071     17       PERSON            0   18      0  \n",
       "2071     19  WORK_OF_ART            0   20      0  \n",
       "2071     68     CARDINAL            0   69      0  \n",
       "2071     69          LOC            0   70      0  \n",
       "2071     72          ORG            0   73      0  \n",
       "2071     74          ORG            0   75      0  \n",
       "2641      1          ORG            0    2      0  \n",
       "2641     15      PRODUCT            0   16      0  \n",
       "2641     18          ORG            0   19      0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't truncate text fields in the display\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "df_dev.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a candidate in the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preprocessors import get_person_text\n",
    "\n",
    "# candidate = tf_dev.loc[2]\n",
    "# person_names = get_person_text(candidate).person_names\n",
    "\n",
    "# print(\"Sentence: \", candidate[\"sentence\"])\n",
    "# print(\"Person 1: \", person_names[0])\n",
    "# print(\"Person 2: \", person_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "In a real application, there is a lot of data preparation, parsing, and database loading that needs to be completed before we generate candidates and dive into writing labeling functions. Here we've pre-generated candidates in a pandas DataFrame object per split (train,dev,test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Function Helpers\n",
    "\n",
    "When writing labeling functions, there are several functions you will use over and over again. In the case of text relation extraction as with this task, common functions include those for fetching text between mentions of the two people in a candidate, examing word windows around person mentions, and so on. We will wrap these functions as `preprocessors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snorkel.preprocess import preprocessor\n",
    "\n",
    "\n",
    "# @preprocessor()\n",
    "# def get_text_between(cand):\n",
    "#     \"\"\"\n",
    "#     Returns the text between the two person mentions in the sentence for a candidate\n",
    "#     \"\"\"\n",
    "#     start = cand.person1_word_idx[1] + 1\n",
    "#     end = cand.person2_word_idx[0]\n",
    "#     cand.text_between = \" \".join(cand.tokens[start:end])\n",
    "#     return cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate PreProcessors\n",
    "\n",
    "For the purposes of the tutorial, we have three fields (`between_tokens`, `person1_right_tokens`, `person2_right_tokens`) preprocessed in the data, which can be used when creating labeling functions. We also provide the following set of `preprocessor`s for this task in `preprocessors.py`, along with the fields these populate.\n",
    "* `get_person_text(cand)`: `person_names`\n",
    "* `get_person_lastnames(cand)`: `person_lastnames`\n",
    "* `get_left_tokens(cand)`: `person1_left_tokens`, `person2_left_tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for language extraction\n",
    "\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjurney/anaconda3/envs/weak/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4702 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('left_text', 'occurred at index 200')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4735\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4736\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4737\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-75bb5b3b5c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLFAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mL_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0mL_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/weakly_supervised_learning_code/src/snorkel/snorkel/labeling/apply/pandas.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, df, progress_bar, fault_tolerant, return_meta)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mlabels_with_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows_to_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_from_row_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_with_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0;31m# Close bar and return pandas calculation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6926\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6927\u001b[0m         )\n\u001b[0;32m-> 6928\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/weakly_supervised_learning_code/src/snorkel/snorkel/labeling/apply/pandas.py\u001b[0m in \u001b[0;36mapply_lfs_to_data_point\u001b[0;34m(x, lfs, f_caller)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/weakly_supervised_learning_code/src/snorkel/snorkel/labeling/apply/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, f, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLabelingFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataPoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfault_tolerant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/weakly_supervised_learning_code/src/snorkel/snorkel/labeling/lf/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-75bb5b3b5c0b>\u001b[0m in \u001b[0;36mkeyword_lookup\u001b[0;34m(x, keywords, field, label)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkeyword_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m\"\"\"Perform lowercase matching for keyword LFs\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-75bb5b3b5c0b>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkeyword_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m\"\"\"Perform lowercase matching for keyword LFs\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4742\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4743\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4744\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4745\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4746\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/weak/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('left_text', 'occurred at index 200')"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import jsonlines, sys\n",
    "from snorkel.labeling import labeling_function, LabelingFunction\n",
    "\n",
    "# Label functions using distant supervision from SPARQL/WikiData for programming languages\n",
    "languages, lower_languages = None, None\n",
    "with jsonlines.open('../../data/programming_languages.jsonl', mode='r') as reader:\n",
    "    languages = [x['name'] for x in reader]\n",
    "    lower_languages = [x.lower() for x in languages]\n",
    "\n",
    "@labeling_function(resources=dict(languages=languages))\n",
    "def lf_matches_wikidata_langs(x, languages):\n",
    "    \"\"\"POSITIVE if the entity_text matches any language in list\"\"\"\n",
    "    return POSITIVE if x.entity_text in languages else ABSTAIN\n",
    "\n",
    "@labeling_function(resources=dict(lower_languages=lower_languages))\n",
    "def lf_lower_matches_wikidata_langs(x, lower_languages):\n",
    "    \"\"\"POSITIVE if the lowercase entity_text matches any lowercase language in list\"\"\"\n",
    "    return POSITIVE if x.entity_text.lower() in lower_languages else ABSTAIN\n",
    "\n",
    "# Label functions using distant supervision from SPARQL/WikiData for operating systems\n",
    "oses, os_parts = [], []\n",
    "with jsonlines.open('../../data/operating_systems.jsonl', mode='r') as reader:\n",
    "    oses = [x['name'].lower() for x in reader]\n",
    "    for os in oses:\n",
    "        for os_part in os.split():\n",
    "            os_parts.append(os_part)\n",
    "\n",
    "@labeling_function(resources=dict(oses=oses))\n",
    "def lf_matches_wikidata_os(x, oses):\n",
    "    \"\"\"NEGATIVE if the lowercase entity_text matches any lowercase OS in the list\"\"\"\n",
    "    return NEGATIVE if x.entity_text.lower() in oses else ABSTAIN\n",
    "\n",
    "@labeling_function(resources=dict(os_parts=os_parts))\n",
    "def lf_matches_wikidata_os_parts(x, os_parts):\n",
    "    \"\"\"NEGATIVE if the lowercase entity_text matches any lowercase OS fragment in the list\"\"\"\n",
    "    return NEGATIVE if x.entity_text.lower() in os_parts else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_left_contains_language(x):\n",
    "    \"\"\"POSITIVE if 'language' appears left of the entity\"\"\"\n",
    "    return POSITIVE if 'language' in x['left_tokens_text'] else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_right_contains_language(x):\n",
    "    \"\"\"POSITIVE if 'language' appears right of the entity\"\"\"\n",
    "    return POSITIVE if 'language' in x['right_tokens_text'] else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_is_framework(x):\n",
    "    \"\"\"NEGATIVE if 'framework' appears to right or left of entity\"\"\"\n",
    "    return NEGATIVE if 'framework' in [y.lower() for y in x['left_tokens_text']] or \\\n",
    "                       'framework' in [y.lower() for y in x['right_tokens_text']] else ABSTAIN\n",
    "\n",
    "starts_rx = re.compile('^\\W')\n",
    "          \n",
    "@labeling_function()\n",
    "def lf_starts_with_char(x):\n",
    "    \"\"\"NEGATIVE if starts with a '-'\"\"\"\n",
    "    return NEGATIVE if starts_rx.match(x['entity_text']) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_wrong_entity_type(x):\n",
    "    return NEGATIVE if x['ent_type'] in ['PERSON', 'NORP', 'FAC', 'GPE', 'LOC', \n",
    "                                         'LAW', 'DATE', 'TIME', 'PERCENT',\n",
    "                                         'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL',] else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_token_count(x):\n",
    "    return NEGATIVE if len(x['entity_text'].split(' ')) > 2 else ABSTAIN\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'POS': 'VERB'}, {'POS': 'ADP'}, {'POS': 'PROPN'}]\n",
    "matcher.add(\"VERB_ADP_PROPN\", None, pattern)\n",
    "\n",
    "@labeling_function()\n",
    "def lf_verb_in_noun(x):\n",
    "    \"\"\"Return positive if the pattern\"\"\"\n",
    "    sp = x['spacy']\n",
    "    matches = matcher(sp)\n",
    "    \n",
    "    found = False\n",
    "    for match_id, start, end in matches:\n",
    "        if start == x['start'] - 2:            \n",
    "            if sp[start].text in ['work', 'written', 'wrote']:                \n",
    "                if sp[start + 1].text in ['in']:\n",
    "                    return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "prefixes = ['internet', 'ie', 'firefox', 'google', 'chrome', 'apple', 'safari', 'webkit', 'gecko', \n",
    "            'opera', 'netscape', 'chromium', ]\n",
    "browser_rx = re.compile(''.join(['^(?:', '|'.join(prefixes), ')']))\n",
    "\n",
    "@labeling_function()\n",
    "def lf_not_browser(x):\n",
    "    \"\"\"Eliminate browser false positives\"\"\"\n",
    "    e = x['entity_text'].lower()\n",
    "    return NEGATIVE if browser_rx.match(e) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_not_operating_system(x):\n",
    "    \"\"\"Eliminate OS false positives\"\"\"\n",
    "\n",
    "# Make keyword LF generation\n",
    "def keyword_lookup(x, keywords, field, label):\n",
    "    \"\"\"Perform lowercase matching for keyword LFs\"\"\"\n",
    "    match = any(word.lower() in x[field].lower() for word in keywords)\n",
    "    if match:\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "def make_keyword_lf(keywords, field='body', label=ABSTAIN):\n",
    "    \"\"\"Given keywords, a field to match against and a label to return, return an keyword LF\"\"\"\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, field=field, label=label),\n",
    "    )\n",
    "\n",
    "# Define keyword LFs\n",
    "language_keyword_lf = make_keyword_lf(['language'], 'left_text', label=POSITIVE)\n",
    "written_keyword_lf = make_keyword_lf(['written'], 'left_text', label=POSITIVE)\n",
    "framework_keyword_lf = make_keyword_lf(['framework', 'package'], 'right_text', label=NEGATIVE)\n",
    "\n",
    "# For each keyword, split on hyphen and create an LF that detects if that tag is present in the data\n",
    "keyword_lfs = OrderedDict()\n",
    "for language in languages:    \n",
    "    keyword_lfs[language] = make_keyword_lf([language], label=POSITIVE)\n",
    "\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    lf_matches_wikidata_langs,\n",
    "    lf_lower_matches_wikidata_langs,\n",
    "    lf_left_contains_language,\n",
    "    # lf_right_contains_language,\n",
    "    lf_is_framework,\n",
    "    lf_starts_with_char,\n",
    "    lf_wrong_entity_type,\n",
    "    lf_token_count,\n",
    "    lf_verb_in_noun,\n",
    "    language_keyword_lf,\n",
    "    written_keyword_lf,\n",
    "    lf_not_browser,\n",
    "] # + list(keyword_lfs.values())\n",
    "applier = PandasLFApplier(lfs)\n",
    "\n",
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "L_dev = applier.apply(df_dev)\n",
    "L_train = applier.apply(df_train)\n",
    "\n",
    "LFAnalysis(L_dev, lfs).lf_summary(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(L_train != ABSTAIN).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.analysis import get_label_buckets\n",
    "\n",
    "buckets = get_label_buckets(y_dev, L_dev[:, 1])\n",
    "\n",
    "df_dev.iloc[buckets[NEGATIVE, POSITIVE]]\n",
    "\n",
    "# df_dev.iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, None, n_epochs=5000, log_freq=500, seed=1337)\n",
    "\n",
    "label_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.analysis import metric_score\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "print(\n",
    "    f\"Label model f1 score: {metric_score(y_dev, preds_dev, probs=probs_dev, metric='f1')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Label model roc-auc: {metric_score(y_dev, preds_dev, probs=probs_dev, metric='roc_auc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "probs_train = label_model.predict_proba(L_train)\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_tokenize(row, window=5):\n",
    "    doc = row['spacy']\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        \n",
    "        l = max(row['start'] - 1 - window, 0)\n",
    "        print(l, row['end'])\n",
    "        row['left_text'] = retokenizer.merge(doc[l : row['start']])\n",
    "#         l = max(row['end'] + 1, 0)\n",
    "#         r = min(row['end'] + 1 + window, len(doc) - 1)\n",
    "        #row['right_text'] = retokenizer.merge(doc[l : r])\n",
    "        return row\n",
    "\n",
    "tf_train = df_train_filtered.apply(re_tokenize, axis=1)\n",
    "tf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Bidirectional,\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Input,\n",
    "    LSTM,\n",
    ")\n",
    "\n",
    "\n",
    "def get_feature_arrays(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Get np arrays of upto max_length tokens and person idxs.\"\"\"\n",
    "    bet = df.between_tokens\n",
    "    left = df.apply(lambda c: c.tokens[: c.person1_word_idx[0]][-4:-1], axis=1)\n",
    "    right = df.person2_right_tokens\n",
    "\n",
    "    def pad_or_truncate(l, max_length=40):\n",
    "        return l[:max_length] + [\"\"] * (max_length - len(l))\n",
    "\n",
    "    left_tokens = np.array(list(map(pad_or_truncate, left)))\n",
    "    bet_tokens = np.array(list(map(pad_or_truncate, bet)))\n",
    "    right_tokens = np.array(list(map(pad_or_truncate, right)))\n",
    "    return left_tokens, bet_tokens, right_tokens\n",
    "\n",
    "\n",
    "def bilstm(\n",
    "    tokens: tf.Tensor,\n",
    "    rnn_state_size: int = 64,\n",
    "    num_buckets: int = 40000,\n",
    "    embed_dim: int = 36,\n",
    "):\n",
    "    ids = tf.strings.to_hash_bucket(tokens, num_buckets)\n",
    "    embedded_input = Embedding(num_buckets, embed_dim)(ids)\n",
    "    return Bidirectional(LSTM(rnn_state_size, activation=tf.nn.relu))(\n",
    "        embedded_input, mask=tf.strings.length(tokens)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    rnn_state_size: int = 64, num_buckets: int = 40000, embed_dim: int = 12\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Return LSTM model for predicting label probabilities.\n",
    "    Args:\n",
    "        rnn_state_size: LSTM state size.\n",
    "        num_buckets: Number of buckets to hash strings to integers.\n",
    "        embed_dim: Size of token embeddings.\n",
    "    Returns:\n",
    "        model: A compiled LSTM model.\n",
    "    \"\"\"\n",
    "    left_ph = Input((None,), dtype=\"string\")\n",
    "    bet_ph = Input((None,), dtype=\"string\")\n",
    "    right_ph = Input((None,), dtype=\"string\")\n",
    "    left_embs = bilstm(left_ph, rnn_state_size, num_buckets, embed_dim)\n",
    "    bet_embs = bilstm(bet_ph, rnn_state_size, num_buckets, embed_dim)\n",
    "    right_embs = bilstm(right_ph, rnn_state_size, num_buckets, embed_dim)\n",
    "    layer = Concatenate(1)([left_embs, bet_embs, right_embs])\n",
    "    layer = Dense(64, activation=tf.nn.relu)(layer)\n",
    "    layer = Dense(32, activation=tf.nn.relu)(layer)\n",
    "    probabilities = Dense(2, activation=tf.nn.softmax)(layer)\n",
    "    model = tf.keras.Model(inputs=[bet_ph, left_ph, right_ph], outputs=probabilities)\n",
    "    model.compile(tf.train.AdagradOptimizer(0.1), \"categorical_crossentropy\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for the `spouse` words appearing to the left of the person mentions\n",
    "# @labeling_function(resources=dict(spouses=spouses), pre=[get_left_tokens])\n",
    "# def lf_husband_wife_left_window(x, spouses):\n",
    "#     if len(set(spouses).intersection(set(x.person1_left_tokens))) > 0:\n",
    "#         return POSITIVE\n",
    "#     elif len(set(spouses).intersection(set(x.person2_left_tokens))) > 0:\n",
    "#         return POSITIVE\n",
    "#     else:\n",
    "#         return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for the person mentions having the same last name\n",
    "# @labeling_function(pre=[get_person_last_names])\n",
    "# def lf_same_last_name(x):\n",
    "#     p1_ln, p2_ln = x.person_lastnames\n",
    "\n",
    "#     if p1_ln and p2_ln and p1_ln == p2_ln:\n",
    "#         return POSITIVE\n",
    "#     return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for the word `married` between person mentions\n",
    "# @labeling_function()\n",
    "# def lf_married(x):\n",
    "#     return POSITIVE if \"married\" in x.between_tokens else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for words that refer to `family` relationships between and to the left of the person mentions\n",
    "# family = {\n",
    "#     \"father\",\n",
    "#     \"mother\",\n",
    "#     \"sister\",\n",
    "#     \"brother\",\n",
    "#     \"son\",\n",
    "#     \"daughter\",\n",
    "#     \"grandfather\",\n",
    "#     \"grandmother\",\n",
    "#     \"uncle\",\n",
    "#     \"aunt\",\n",
    "#     \"cousin\",\n",
    "# }\n",
    "# family = family.union({f + \"-in-law\" for f in family})\n",
    "\n",
    "\n",
    "# @labeling_function(resources=dict(family=family))\n",
    "# def lf_familial_relationship(x, family):\n",
    "#     return NEGATIVE if len(family.intersection(set(x.between_tokens))) > 0 else ABSTAIN\n",
    "\n",
    "\n",
    "# @labeling_function(resources=dict(family=family), pre=[get_left_tokens])\n",
    "# def lf_family_left_window(x, family):\n",
    "#     if len(set(family).intersection(set(x.person1_left_tokens))) > 0:\n",
    "#         return NEGATIVE\n",
    "#     elif len(set(family).intersection(set(x.person2_left_tokens))) > 0:\n",
    "#         return NEGATIVE\n",
    "#     else:\n",
    "#         return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for `other` relationship words between person mentions\n",
    "# other = {\"boyfriend\", \"girlfriend\", \"boss\", \"employee\", \"secretary\", \"co-worker\"}\n",
    "\n",
    "\n",
    "# @labeling_function(resources=dict(other=other))\n",
    "# def lf_other_relationship(x, other):\n",
    "#     return NEGATIVE if len(other.intersection(set(x.between_tokens))) > 0 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distant Supervision Labeling Functions\n",
    "\n",
    "In addition to using factories that encode pattern matching heuristics, we can also write labeling functions that _distantly supervise_ data points. Here, we'll load in a list of known spouse pairs and check to see if the pair of persons in a candidate matches one of these.\n",
    "\n",
    "[**DBpedia**](http://wiki.dbpedia.org/): Our database of known spouses comes from DBpedia, which is a community-driven resource similar to Wikipedia but for curating structured data. We'll use a preprocessed snapshot as our knowledge base for all labeling function development.\n",
    "\n",
    "We can look at some of the example entries from DBPedia and use them in a simple distant supervision labeling function.\n",
    "\n",
    "Make sure `dbpedia.pkl` is in the `spouse/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/dbpedia.pkl\", \"rb\") as f:\n",
    "#     known_spouses = pickle.load(f)\n",
    "\n",
    "# list(known_spouses)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @labeling_function(resources=dict(known_spouses=known_spouses), pre=[get_person_text])\n",
    "# def lf_distant_supervision(x, known_spouses):\n",
    "#     p1, p2 = x.person_names\n",
    "#     if (p1, p2) in known_spouses or (p2, p1) in known_spouses:\n",
    "#         return POSITIVE\n",
    "#     else:\n",
    "#         return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preprocessors import last_name\n",
    "\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set(\n",
    "#     [\n",
    "#         (last_name(x), last_name(y))\n",
    "#         for x, y in known_spouses\n",
    "#         if last_name(x) and last_name(y)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# @labeling_function(resources=dict(last_names=last_names), pre=[get_person_last_names])\n",
    "# def lf_distant_supervision_last_names(x, last_names):\n",
    "#     p1_ln, p2_ln = x.person_lastnames\n",
    "\n",
    "#     return (\n",
    "#         POSITIVE\n",
    "#         if (p1_ln != p2_ln)\n",
    "#         and ((p1_ln, p2_ln) in last_names or (p2_ln, p1_ln) in last_names)\n",
    "#         else ABSTAIN\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Labeling Functions to the Data\n",
    "We create a list of labeling functions and apply them to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "# lfs = [\n",
    "#     lf_husband_wife,\n",
    "#     lf_husband_wife_left_window,\n",
    "#     lf_same_last_name,\n",
    "#     lf_married,\n",
    "#     lf_familial_relationship,\n",
    "#     lf_family_left_window,\n",
    "#     lf_other_relationship,\n",
    "#     lf_distant_supervision,\n",
    "#     lf_distant_supervision_last_names,\n",
    "# ]\n",
    "# applier = PandasLFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "# from snorkel.labeling import LFAnalysis\n",
    "\n",
    "# L_dev = applier.apply(df_dev)\n",
    "# L_train = applier.apply(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFAnalysis(L_dev, lfs).lf_summary(Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Label Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their weights and combine their outputs. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "# from snorkel.labeling import LabelModel\n",
    "\n",
    "# label_model = LabelModel(cardinality=2, verbose=True)\n",
    "# label_model.fit(L_train, Y_dev, n_epochs=5000, log_freq=500, seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Model Metrics\n",
    "Since our dataset is highly unbalanced (91% of the labels are negative), even a trivial baseline that always outputs negative can get a high accuracy. So we evaluate the label model using the F1 score and ROC-AUC rather than accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.analysis import metric_score\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "print(\n",
    "    f\"Label model f1 score: {metric_score(y_dev, preds_dev, probs=probs_dev, metric='f1')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Label model roc-auc: {metric_score(y_dev, preds_dev, probs=probs_dev, metric='roc_auc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Part 4: Training our End Extraction Model\n",
    "\n",
    "In this final section of the tutorial, we'll use our noisy training labels to train our end machine learning model. We start by filtering out training data points which did not recieve a label from any LF, as these data points contain no signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "probs_train = label_model.predict_proba(L_train)\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a simple [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) network for classifying candidates. `tf_model` contains functions for processing features and building the keras model for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "from tf_model import get_model, get_feature_arrays\n",
    "from utils import get_n_epochs\n",
    "\n",
    "X_train = get_feature_arrays(df_train_filtered)\n",
    "model = get_model()\n",
    "batch_size = 64\n",
    "model.fit(X_train, probs_train_filtered, batch_size=batch_size, epochs=get_n_epochs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the trained model by measuring its F1 score and ROC_AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_feature_arrays(df_test)\n",
    "probs_test = model.predict(X_test)\n",
    "preds_test = probs_to_preds(probs_test)\n",
    "print(\n",
    "    f\"Test F1 when trained with soft labels: {metric_score(Y_test, preds=preds_test, metric='f1')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test ROC-AUC when trained with soft labels: {metric_score(Y_test, probs=probs_test, metric='roc_auc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this tutorial, we showed how Snorkel can be used for Information Extraction. We demonstrated how to create LFs that leverage keywords and external knowledge bases (distant supervision). Finally, we showed how a model trained using the probabilistic outputs of the Label Model can achieve comparable performance while generalizing to all data points."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
